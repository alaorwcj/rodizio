# Avalia√ß√£o: Migra√ß√£o de db.json para PostgreSQL

**Data da Avalia√ß√£o:** 26 de outubro de 2025  
**Status:** An√°lise de Viabilidade - SEM ALTERA√á√ïES

---

## 1. RESUMO EXECUTIVO

‚úÖ **MIGRA√á√ÉO √â VI√ÅVEL E RECOMENDADA**

A migra√ß√£o do atual sistema de persist√™ncia baseado em arquivo JSON (`db.json`) para PostgreSQL √© **totalmente vi√°vel** e trar√° **benef√≠cios significativos** para a aplica√ß√£o.

### Principais Vantagens
- ‚úÖ Melhor desempenho em opera√ß√µes de leitura/escrita
- ‚úÖ Transa√ß√µes ACID garantidas
- ‚úÖ Suporte nativo a concorr√™ncia
- ‚úÖ Queries mais eficientes e indexa√ß√£o
- ‚úÖ Backup e recupera√ß√£o mais robustos
- ‚úÖ Escalabilidade horizontal futura

### Complexidade da Migra√ß√£o
- üü° **M√âDIA** - Requer planejamento mas √© execut√°vel
- Tempo estimado: 16-24 horas de trabalho
- Baixo risco se bem planejado

---

## 2. AN√ÅLISE DO ESTADO ATUAL

### 2.1 Estrutura do Banco de Dados Atual (db.json)

**Arquivo:** `/root/app/rodizio/data/db.json`
- **Tamanho:** 7.030 linhas
- **Formato:** JSON hier√°rquico aninhado
- **Persist√™ncia:** Arquivo texto com locking (portalocker)

**Estrutura de Dados Identificada:**

```json
{
  "sistema": {...},           // Metadados do sistema
  "regionais": {              // Hierarquia: Regional > Sub-Regional > Comum
    "gru": {
      "sub_regionais": {
        "santa_isabel": {
          "comuns": {
            "vila_paula": {
              "organistas": [...],
              "indisponibilidades": [...],
              "escala": [...],
              "escala_rjm": [...],
              "trocas": [...],
              "config": {...}
            }
          }
        }
      }
    }
  },
  "usuarios": [...],          // Usu√°rios do sistema
  "logs": [...],              // Logs operacionais
  "logs_auditoria": [...],    // Logs de auditoria
  "escala_rjm": [...],        // Escalas RJM globais
  "escala": [...],            // Escalas globais
  "escala_publicada_em": "...",
  "escala_publicada_por": "..."
}
```

### 2.2 Depend√™ncias Atuais

**Framework:** Flask 3.0.0
**Persist√™ncia Atual:**
- JSON puro (stdlib)
- `portalocker==2.8.2` - Lock de arquivo para concorr√™ncia
- Opera√ß√µes s√≠ncronas de I/O

**Outras Depend√™ncias Relevantes:**
```
Flask==3.0.0
Flask-Login==0.6.3
Werkzeug==3.0.1
```

### 2.3 Infraestrutura Existente

**Docker Compose Atual:**
- Servi√ßo: `rodizio-app` (Flask)
- Servi√ßo: `nginx` (Reverse proxy)
- Servi√ßo: `certbot` (SSL)
- Volume: `./data:/app/data` (persist√™ncia JSON)

**PostgreSQL:**
- ‚úÖ J√° instalado localmente
- üÜï Criar nova base: `rodizio`

---

## 3. SCHEMA PROPOSTO PARA POSTGRESQL

### 3.1 Script de Migra√ß√£o Existente

J√° existe um script parcial de migra√ß√£o para SQLite em:
üìÑ `/root/app/rodizio/scripts/migrate_json_to_sqlite.py`

Este script pode ser adaptado para PostgreSQL com modifica√ß√µes m√≠nimas.

### 3.2 Modelo de Dados Relacional

```sql
-- Hierarquia Organizacional
CREATE TABLE regionais (
  id VARCHAR(50) PRIMARY KEY,
  nome VARCHAR(200) NOT NULL,
  ativo BOOLEAN NOT NULL DEFAULT TRUE,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE TABLE sub_regionais (
  id VARCHAR(50) PRIMARY KEY,
  regional_id VARCHAR(50) NOT NULL REFERENCES regionais(id) ON DELETE CASCADE,
  nome VARCHAR(200) NOT NULL,
  ativo BOOLEAN NOT NULL DEFAULT TRUE,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE TABLE comuns (
  id VARCHAR(50) PRIMARY KEY,
  sub_regional_id VARCHAR(50) NOT NULL REFERENCES sub_regionais(id) ON DELETE CASCADE,
  nome VARCHAR(200) NOT NULL,
  endereco TEXT,
  cidade VARCHAR(100),
  ativo BOOLEAN NOT NULL DEFAULT TRUE,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Organistas
CREATE TABLE organistas (
  id VARCHAR(50) PRIMARY KEY,
  comum_id VARCHAR(50) NOT NULL REFERENCES comuns(id) ON DELETE CASCADE,
  nome VARCHAR(200) NOT NULL,
  password_hash TEXT NOT NULL,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE TABLE organista_tipos (
  organista_id VARCHAR(50) NOT NULL REFERENCES organistas(id) ON DELETE CASCADE,
  tipo VARCHAR(50) NOT NULL,
  PRIMARY KEY (organista_id, tipo)
);

CREATE TABLE organista_dias_permitidos (
  organista_id VARCHAR(50) NOT NULL REFERENCES organistas(id) ON DELETE CASCADE,
  dia VARCHAR(20) NOT NULL,
  PRIMARY KEY (organista_id, dia)
);

-- Indisponibilidades
CREATE TABLE indisponibilidades (
  id SERIAL PRIMARY KEY,
  comum_id VARCHAR(50) NOT NULL REFERENCES comuns(id) ON DELETE CASCADE,
  organista_id VARCHAR(50) NOT NULL REFERENCES organistas(id) ON DELETE CASCADE,
  data DATE NOT NULL,
  motivo TEXT,
  autor VARCHAR(50),
  status VARCHAR(20),
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Escalas
CREATE TABLE escala (
  id SERIAL PRIMARY KEY,
  comum_id VARCHAR(50) NOT NULL REFERENCES comuns(id) ON DELETE CASCADE,
  data DATE NOT NULL,
  dia_semana VARCHAR(20),
  meia_hora VARCHAR(200),
  culto VARCHAR(200),
  criado_em TIMESTAMPTZ DEFAULT NOW(),
  publicado_em TIMESTAMPTZ,
  publicado_por VARCHAR(50)
);

CREATE TABLE escala_rjm (
  id VARCHAR(100) PRIMARY KEY,
  comum_id VARCHAR(50) NOT NULL REFERENCES comuns(id) ON DELETE CASCADE,
  data DATE NOT NULL,
  dia_semana VARCHAR(20),
  organista VARCHAR(200),
  criado_em TIMESTAMPTZ DEFAULT NOW()
);

-- Configura√ß√µes
CREATE TABLE comum_config (
  comum_id VARCHAR(50) PRIMARY KEY REFERENCES comuns(id) ON DELETE CASCADE,
  periodo_inicio DATE,
  periodo_fim DATE,
  fechamento_publicacao_dias INTEGER,
  dias_culto JSONB,  -- Array de dias permitidos
  horarios JSONB,    -- Configura√ß√µes de hor√°rios
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Sistema de Trocas
CREATE TABLE trocas (
  id VARCHAR(100) PRIMARY KEY,
  comum_id VARCHAR(50) NOT NULL REFERENCES comuns(id) ON DELETE CASCADE,
  status VARCHAR(20),
  modalidade VARCHAR(50),
  tipo VARCHAR(50),
  data DATE,
  slot VARCHAR(50),
  solicitante_id VARCHAR(50),
  solicitante_nome VARCHAR(200),
  alvo_id VARCHAR(50),
  alvo_nome VARCHAR(200),
  motivo TEXT,
  criado_em TIMESTAMPTZ DEFAULT NOW(),
  atualizado_em TIMESTAMPTZ DEFAULT NOW()
);

CREATE TABLE trocas_historico (
  id SERIAL PRIMARY KEY,
  troca_id VARCHAR(100) NOT NULL REFERENCES trocas(id) ON DELETE CASCADE,
  quando TIMESTAMPTZ NOT NULL,
  acao VARCHAR(50),
  por VARCHAR(200)
);

-- Usu√°rios do Sistema
CREATE TABLE usuarios (
  id VARCHAR(50) PRIMARY KEY,
  nome VARCHAR(200) NOT NULL,
  password_hash TEXT NOT NULL,
  tipo VARCHAR(50) NOT NULL,  -- master, admin_regional, encarregado_sub, etc
  nivel VARCHAR(50) NOT NULL,  -- sistema, regional, sub_regional, comum
  contexto_id VARCHAR(50),     -- ID da regional/sub/comum
  ativo BOOLEAN DEFAULT TRUE,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Auditoria
CREATE TABLE logs_auditoria (
  id VARCHAR(100) PRIMARY KEY,
  timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  tipo VARCHAR(50),
  categoria VARCHAR(50),
  acao VARCHAR(100),
  descricao TEXT,
  usuario_id VARCHAR(50),
  usuario_nome VARCHAR(200),
  usuario_tipo VARCHAR(50),
  regional_id VARCHAR(50),
  sub_regional_id VARCHAR(50),
  comum_id VARCHAR(50),
  status VARCHAR(20),
  ip VARCHAR(45),
  user_agent TEXT,
  dados_antes JSONB,
  dados_depois JSONB
);

-- √çndices para Performance
CREATE INDEX idx_organistas_comum ON organistas(comum_id);
CREATE INDEX idx_indisponibilidades_comum_data ON indisponibilidades(comum_id, data);
CREATE INDEX idx_indisponibilidades_organista ON indisponibilidades(organista_id);
CREATE INDEX idx_escala_comum_data ON escala(comum_id, data);
CREATE INDEX idx_escala_rjm_comum_data ON escala_rjm(comum_id, data);
CREATE INDEX idx_trocas_comum_status ON trocas(comum_id, status);
CREATE INDEX idx_logs_timestamp ON logs_auditoria(timestamp DESC);
CREATE INDEX idx_logs_usuario ON logs_auditoria(usuario_id);
CREATE INDEX idx_logs_comum ON logs_auditoria(comum_id);
```

### 3.3 Vantagens do Schema PostgreSQL

1. **Normaliza√ß√£o Adequada**
   - Elimina redund√¢ncia de dados
   - Integridade referencial com FOREIGN KEYS
   - Triggers para atualiza√ß√£o autom√°tica de timestamps

2. **Performance**
   - √çndices espec√≠ficos para queries frequentes
   - JSONB para dados semi-estruturados (config, logs)
   - Queries otimizadas vs varredura em JSON

3. **Transa√ß√µes ACID**
   - Elimina necessidade de file locking manual
   - Rollback autom√°tico em caso de erro
   - Consist√™ncia garantida

4. **Recursos Avan√ßados**
   - Full-text search nativo
   - Particionamento de tabelas (futuro)
   - Replica√ß√£o e backup incremental

---

## 4. PLANO DE MIGRA√á√ÉO

### 4.1 Fase 1: Prepara√ß√£o (2-3 horas)

#### 4.1.1 Instala√ß√£o de Depend√™ncias
```bash
# Adicionar ao requirements.txt
psycopg2-binary==2.9.9  # Driver PostgreSQL
SQLAlchemy==2.0.23      # ORM (opcional, mas recomendado)
alembic==1.13.0         # Migrations (recomendado)
```

#### 4.1.2 Criar Base de Dados
```sql
-- No PostgreSQL local
CREATE DATABASE rodizio
  WITH OWNER = postgres
  ENCODING = 'UTF8'
  LC_COLLATE = 'pt_BR.UTF-8'
  LC_CTYPE = 'pt_BR.UTF-8'
  TEMPLATE = template0;
```

#### 4.1.3 Configurar Vari√°veis de Ambiente
```bash
# .env ou docker-compose.yml
DATABASE_URL=postgresql://usuario:senha@localhost:5432/rodizio
```

### 4.2 Fase 2: Implementa√ß√£o da Camada de Dados (6-8 horas)

#### 4.2.1 Criar M√≥dulo de Database
```
/root/app/rodizio/
  ‚îú‚îÄ‚îÄ database.py          # Conex√£o e engine
  ‚îú‚îÄ‚îÄ models.py            # Modelos SQLAlchemy (ORM)
  ‚îî‚îÄ‚îÄ repositories/        # Padr√£o Repository
      ‚îú‚îÄ‚îÄ __init__.py
      ‚îú‚îÄ‚îÄ regional_repo.py
      ‚îú‚îÄ‚îÄ organista_repo.py
      ‚îú‚îÄ‚îÄ escala_repo.py
      ‚îî‚îÄ‚îÄ auditoria_repo.py
```

#### 4.2.2 Implementar Repositories
- Abstrair l√≥gica de acesso a dados
- Manter interfaces compat√≠veis com c√≥digo atual
- Facilitar testes unit√°rios

### 4.3 Fase 3: Refatora√ß√£o do app.py (6-8 horas)

#### Substituir:
```python
# ANTES
db = load_db()
db['regionais'][rid]['sub_regionais'][sid]...
save_db(db)

# DEPOIS
from repositories import RegionalRepository
repo = RegionalRepository()
regional = repo.get_by_id(rid)
sub = repo.get_sub_regional(rid, sid)
```

#### Principais Mudan√ßas:
1. Substituir `load_db()` / `save_db()` por repositories
2. Converter navega√ß√£o JSON para queries ORM
3. Adaptar fun√ß√µes de busca/filtro
4. Implementar transa√ß√µes

### 4.4 Fase 4: Script de Migra√ß√£o de Dados (3-4 horas)

Adaptar `/root/app/rodizio/scripts/migrate_json_to_sqlite.py` para PostgreSQL:

```python
# migrate_json_to_postgres.py
import psycopg2
from psycopg2.extras import Json

def migrate_data():
    # 1. Backup do db.json
    # 2. Conectar PostgreSQL
    # 3. Criar schema
    # 4. Migrar dados hierarquia
    # 5. Migrar organistas
    # 6. Migrar escalas
    # 7. Migrar logs
    # 8. Validar migra√ß√£o
    pass
```

### 4.5 Fase 5: Atualizar Docker Compose (1 hora)

```yaml
services:
  postgres:
    image: postgres:16-alpine
    container_name: rodizio-postgres
    environment:
      POSTGRES_DB: rodizio
      POSTGRES_USER: rodizio_user
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=pt_BR.UTF-8"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - rodizio-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U rodizio_user"]
      interval: 10s
      timeout: 5s
      retries: 5

  rodizio-app:
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      DATABASE_URL: postgresql://rodizio_user:${DB_PASSWORD}@postgres:5432/rodizio

volumes:
  postgres_data:
```

### 4.6 Fase 6: Testes (2-3 horas)

1. **Testes de Unidade**
   - Repositories
   - Modelos ORM

2. **Testes de Integra√ß√£o**
   - Autentica√ß√£o
   - Cria√ß√£o de escalas
   - Gest√£o de indisponibilidades
   - Trocas
   - Auditoria

3. **Teste de Migra√ß√£o**
   - Comparar dados JSON vs PostgreSQL
   - Validar integridade

---

## 5. RISCOS E MITIGA√á√ïES

### 5.1 Riscos Identificados

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|--------------|---------|-----------|
| Perda de dados durante migra√ß√£o | Baixa | Alto | Backup completo antes; valida√ß√£o p√≥s-migra√ß√£o |
| Incompatibilidade de c√≥digo | M√©dia | M√©dio | Testes extensivos; migra√ß√£o gradual |
| Downtime da aplica√ß√£o | M√©dia | M√©dio | Migra√ß√£o em ambiente de staging primeiro |
| Performance inicial ruim | Baixa | Baixo | √çndices adequados; tuning p√≥s-migra√ß√£o |
| Conex√µes n√£o fechadas | M√©dia | M√©dio | Connection pooling; context managers |

### 5.2 Estrat√©gias de Mitiga√ß√£o

1. **Backup Triplo**
   - Backup do db.json atual
   - Export SQL do PostgreSQL
   - Snapshot do volume Docker

2. **Migra√ß√£o Gradual**
   - Ambiente de desenvolvimento primeiro
   - Testes completos
   - Staging com dados reais
   - Produ√ß√£o com janela de manuten√ß√£o

3. **Rollback Plan**
   - Manter db.json como fallback
   - Script de rollback automatizado
   - Documentar procedimento de revers√£o

---

## 6. CRONOGRAMA ESTIMADO

### Op√ß√£o 1: Migra√ß√£o Total (1 sprint - 2 semanas)
```
Semana 1:
‚îú‚îÄ Dia 1-2: Prepara√ß√£o e setup PostgreSQL
‚îú‚îÄ Dia 3-4: Implementa√ß√£o camada de dados
‚îî‚îÄ Dia 5: Refatora√ß√£o inicial

Semana 2:
‚îú‚îÄ Dia 1-2: Refatora√ß√£o completa
‚îú‚îÄ Dia 3: Script de migra√ß√£o
‚îú‚îÄ Dia 4: Testes
‚îî‚îÄ Dia 5: Deploy e valida√ß√£o
```

### Op√ß√£o 2: Migra√ß√£o Incremental (2 sprints - 4 semanas)
```
Sprint 1 (Setup + Leitura):
‚îú‚îÄ Prepara√ß√£o PostgreSQL
‚îú‚îÄ Implementar camada de dados
‚îú‚îÄ Migra√ß√£o de queries de leitura
‚îî‚îÄ Testes parciais

Sprint 2 (Escrita + Migra√ß√£o):
‚îú‚îÄ Migra√ß√£o de queries de escrita
‚îú‚îÄ Script de migra√ß√£o de dados
‚îú‚îÄ Testes completos
‚îî‚îÄ Deploy gradual
```

---

## 7. CUSTO-BENEF√çCIO

### Investimento Necess√°rio
- ‚è±Ô∏è Tempo: 16-24 horas de desenvolvimento
- üí∞ Infraestrutura: Minimal (PostgreSQL j√° dispon√≠vel)
- üìö Curva de aprendizado: Baixa (tecnologias conhecidas)

### Benef√≠cios Esperados
- ‚ö° **Performance**: 10-100x mais r√°pido em queries complexas
- üîí **Confiabilidade**: Transa√ß√µes ACID, sem corrup√ß√£o de dados
- üìà **Escalabilidade**: Suporta crescimento sem refatora√ß√£o
- üõ†Ô∏è **Manutenibilidade**: C√≥digo mais limpo e test√°vel
- üîç **Observabilidade**: Logs de query, explain plans, monitoring

### ROI (Return on Investment)
- **Curto prazo** (1-3 meses): Menos bugs, deploys mais confi√°veis
- **M√©dio prazo** (6 meses): Menor tempo de desenvolvimento de features
- **Longo prazo** (1+ ano): Escalabilidade sem reescrita

---

## 8. RECOMENDA√á√ïES

### ‚úÖ Recomendamos a Migra√ß√£o pelos seguintes motivos:

1. **Funda√ß√£o S√≥lida**
   - PostgreSQL √© padr√£o da ind√∫stria
   - Suporte de longo prazo garantido
   - Comunidade ativa

2. **Crescimento Futuro**
   - Sistema est√° em fase de crescimento
   - Mais comuns e usu√°rios ser√£o adicionados
   - JSON n√£o escalar√° bem

3. **Manutenibilidade**
   - C√≥digo atual est√° acoplado ao JSON
   - Dificulta testes e manuten√ß√£o
   - Refatora√ß√£o trar√° benef√≠cios al√©m do DB

4. **Timing Adequado**
   - Sistema ainda em desenvolvimento ativo
   - Base de c√≥digo relativamente pequena
   - Melhor fazer agora que depois

### üéØ Abordagem Recomendada

**MIGRA√á√ÉO INCREMENTAL EM 2 FASES:**

**Fase 1 (2 semanas):**
- Setup PostgreSQL
- Implementar camada de dados com SQLAlchemy
- Migrar opera√ß√µes de leitura
- Manter escrita em JSON (fallback)

**Fase 2 (2 semanas):**
- Migrar opera√ß√µes de escrita
- Executar migra√ß√£o de dados
- Testes exaustivos
- Deploy em produ√ß√£o

### üìã Pr√≥ximos Passos Sugeridos

1. ‚úÖ **Aprova√ß√£o desta avalia√ß√£o**
2. üîß **Setup do ambiente PostgreSQL local**
3. üìù **Criar branch `feature/postgres-migration`**
4. üèóÔ∏è **Implementar schema e models**
5. üîÑ **Refatora√ß√£o incremental**
6. ‚úÖ **Testes e valida√ß√£o**
7. üöÄ **Deploy gradual**

---

## 9. CONSIDERA√á√ïES T√âCNICAS ADICIONAIS

### 9.1 Connection Pooling
```python
# Usar SQLAlchemy com pool de conex√µes
from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool

engine = create_engine(
    DATABASE_URL,
    poolclass=QueuePool,
    pool_size=10,
    max_overflow=20,
    pool_pre_ping=True  # Verificar conex√µes antes de usar
)
```

### 9.2 Migrations com Alembic
```bash
# Gerenciar mudan√ßas de schema
alembic init migrations
alembic revision --autogenerate -m "Initial schema"
alembic upgrade head
```

### 9.3 Backup Automatizado
```bash
# Cronjob para backup di√°rio
0 2 * * * pg_dump -U rodizio_user rodizio | gzip > /backups/rodizio_$(date +\%Y\%m\%d).sql.gz
```

### 9.4 Monitoring
```python
# Usar pg_stat_statements
CREATE EXTENSION pg_stat_statements;

# Monitorar queries lentas
SELECT * FROM pg_stat_statements 
WHERE mean_exec_time > 1000 
ORDER BY mean_exec_time DESC;
```

---

## 10. CONCLUS√ÉO

A migra√ß√£o de `db.json` para PostgreSQL √© **VI√ÅVEL**, **RECOMENDADA** e deve ser **PRIORIZADA** no roadmap de desenvolvimento.

**Veredito Final: üü¢ APROVADO PARA EXECU√á√ÉO**

### Fatores de Sucesso
- ‚úÖ PostgreSQL j√° dispon√≠vel localmente
- ‚úÖ Script de migra√ß√£o existente (SQLite) pode ser adaptado
- ‚úÖ Estrutura de dados bem definida
- ‚úÖ Benef√≠cios superam custos significativamente
- ‚úÖ Timing ideal para migra√ß√£o

### Pr√≥xima A√ß√£o Recomendada
**Iniciar Fase 1 da migra√ß√£o:**
1. Criar base `rodizio` no PostgreSQL local
2. Instalar depend√™ncias Python (psycopg2, SQLAlchemy)
3. Implementar schema e models b√°sicos
4. Validar conex√£o e queries simples

---

**Documento preparado por:** GitHub Copilot  
**Data:** 26 de outubro de 2025  
**Vers√£o:** 1.0  
**Status:** Aguardando aprova√ß√£o para execu√ß√£o
